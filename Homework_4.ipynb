{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with Python\n",
    "\n",
    "Hopefully now you are feeling a bit more comfortable with Python, Kaggle, and modeling. \n",
    "\n",
    "The next kaggle project:\n",
    "\n",
    "https://www.kaggle.com/c/costa-rican-household-poverty-prediction\n",
    "\n",
    "### Grading\n",
    "\n",
    "This homework is due **Nov. 06, 2018 by 4:00pn Utah time.** By that time, you need to have committed all your code to your github and submitted a link to your work to the TA. We can see on your Github account when you last committed code. :)\n",
    "\n",
    "Rubric:\n",
    "\n",
    "* Code Quality - 10%\n",
    "* Storytelling - 10%\n",
    "* Result on Kaggle - 5%\n",
    "* Describing, Cleaning, and Visualizing data - 25%\n",
    "* Modeling - 50%\n",
    "\n",
    "More specifically, for modeling we will look for: \n",
    "\n",
    "* Model Selection: Did you try multiple models? Why did you choose these models? How do they work? What are they assumptions? And how did you test/account for them? How did you select hyper-parameters?\n",
    "* Model evaluation: Did you evaluate your model on multiple metrics? Where does your model do well? Where could it be improved? How are the metrics different?\n",
    "* Model interpretation: What do the model results tell you? Which variables are important? High bias or variance and how did you / could you fix this? How confident are you in your results? \n",
    "* Model usefulness: Do you think your final model was useful? If so, how would you recommend using it? Convince us, that if we were a company, we would feel comfortable using your model with our users. Think about edge cases as well - are there certain areas that the model performs poorly on? Best on? How would you handle these cases, if say Zillow wanted to leverage your model realizing that bad recommendations on sale prices would hurt customer trust and your brand. This section also falls into the storytelling aspect of the grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "# cleaning imports\n",
    "from scipy.stats import skew\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "# model imports\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.linear_model import Ridge, RidgeCV, ElasticNet, LassoCV, LassoLarsCV, ElasticNet, Lasso,  BayesianRidge, SGDRegressor, LassoLars\n",
    "import xgboost\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "#import lightgbm\n",
    "# validation imports\n",
    "from sklearn.metrics import mean_squared_error, classification_report, roc_auc_score\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data all spic and span ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wanna keep that ID\n",
    "train_ID = train['Id']\n",
    "test_ID = test['Id']\n",
    "#train = train_.drop('Id', 1).copy()\n",
    "#test = test.drop('Id', 1).copy()\n",
    "y = train['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    9557.000000\n",
       "mean        3.302292\n",
       "std         1.009565\n",
       "min         1.000000\n",
       "25%         3.000000\n",
       "50%         4.000000\n",
       "75%         4.000000\n",
       "max         4.000000\n",
       "Name: Target, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's gander at the data\n",
    "y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    0.627394\n",
       "2    0.167103\n",
       "3    0.126504\n",
       "1    0.079000\n",
       "Name: Target, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It seems 4 is an overwhelming majority but let's see how much\n",
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   0.,  755., 1597., 1209., 5996.,    0.]),\n",
       " array([0, 1, 2, 3, 4, 5, 6]),\n",
       " <a list of 6 Patch objects>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAETJJREFUeJzt3X+MXWWdx/H3Rwrq4o+CDIS0ZYuxccVNBDIBDIlxwS0FjOUPSTC70hCS/sMazG7igv80giT4jyjJSkJo3eKiSFBCo0RsCsT1D34UQRAK2y6ydFKkdQsoS9SA3/1jnuqA086d6cxcOs/7ldycc77nOfc8T5r2c89zzz1NVSFJ6s/bht0BSdJwGACS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkTi0adgcO5Jhjjqnly5cPuxuSdEh5+OGHf11VI1O1e0sHwPLly9m6deuwuyFJh5Qk/zNIO6eAJKlTBoAkdcoAkKROGQCS1CkDQJI6NVAAJFmc5PYkTyXZluSjSY5OsjnJ9rY8qrVNkuuT7EjyWJJTJ7zPmtZ+e5I1czUoSdLUBr0C+Drwo6r6G+AjwDbgCmBLVa0AtrRtgHOBFe21FrgBIMnRwDrgdOA0YN2+0JAkzb8pAyDJe4CPAesBquoPVfUSsBrY2JptBC5o66uBm2vc/cDiJMcD5wCbq2pvVb0IbAZWzepoJEkDG+QK4P3AHuCbSR5JclOSI4Hjqup5gLY8trVfAuyccPxYq+2vLkkagkF+CbwIOBX4XFU9kOTr/Hm6ZzKZpFYHqL/x4GQt41NHnHDCCQN0T9LBWH7FD4fdhVnz7LXnD7sLh5RBrgDGgLGqeqBt3854ILzQpnZoy90T2i+bcPxSYNcB6m9QVTdW1WhVjY6MTPkoC0nSDE0ZAFX1K2Bnkg+20tnAk8AmYN+dPGuAO9v6JuDidjfQGcDLbYrobmBlkqPal78rW02SNASDPgzuc8AtSY4AngEuYTw8bktyKfAccGFrexdwHrADeLW1par2JrkaeKi1u6qq9s7KKCRJ0zZQAFTVo8DoJLvOnqRtAZft5302ABum00FJ0tzwl8CS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1KmBAiDJs0keT/Jokq2tdnSSzUm2t+VRrZ4k1yfZkeSxJKdOeJ81rf32JGvmZkiSpEFM5wrg76rq5KoabdtXAFuqagWwpW0DnAusaK+1wA0wHhjAOuB04DRg3b7QkCTNv4OZAloNbGzrG4ELJtRvrnH3A4uTHA+cA2yuqr1V9SKwGVh1EOeXJB2EQQOggB8neTjJ2lY7rqqeB2jLY1t9CbBzwrFjrba/uiRpCBYN2O7MqtqV5Fhgc5KnDtA2k9TqAPU3HjweMGsBTjjhhAG7J0maroGuAKpqV1vuBu5gfA7/hTa1Q1vubs3HgGUTDl8K7DpA/c3nurGqRqtqdGRkZHqjkSQNbMoASHJkknfvWwdWAr8ANgH77uRZA9zZ1jcBF7e7gc4AXm5TRHcDK5Mc1b78XdlqkqQhGGQK6DjgjiT72n+7qn6U5CHgtiSXAs8BF7b2dwHnATuAV4FLAKpqb5KrgYdau6uqau+sjUSSNC1TBkBVPQN8ZJL6/wJnT1Iv4LL9vNcGYMP0uylJmm3+EliSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnBg6AJIcleSTJD9r2iUkeSLI9yXeTHNHqb2/bO9r+5RPe48pWfzrJObM9GEnS4KZzBXA5sG3C9leA66pqBfAicGmrXwq8WFUfAK5r7UhyEnAR8GFgFfCNJIcdXPclSTM1UAAkWQqcD9zUtgOcBdzemmwELmjrq9s2bf/Zrf1q4Naq+n1V/RLYAZw2G4OQJE3foFcAXwO+APyxbb8PeKmqXmvbY8CStr4E2AnQ9r/c2v+pPskxkqR5NmUAJPkksLuqHp5YnqRpTbHvQMdMPN/aJFuTbN2zZ89U3ZMkzdAgVwBnAp9K8ixwK+NTP18DFidZ1NosBXa19TFgGUDb/15g78T6JMf8SVXdWFWjVTU6MjIy7QFJkgYzZQBU1ZVVtbSqljP+Je49VfUPwL3Ap1uzNcCdbX1T26btv6eqqtUvancJnQisAB6ctZFIkqZl0dRN9utfgVuTfBl4BFjf6uuBbyXZwfgn/4sAquqJJLcBTwKvAZdV1esHcX5J0kGYVgBU1X3AfW39GSa5i6eqfgdcuJ/jrwGumW4nJUmzz18CS1KnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6tSUAZDkHUkeTPLzJE8k+VKrn5jkgSTbk3w3yRGt/va2vaPtXz7hva5s9aeTnDNXg5IkTW2QK4DfA2dV1UeAk4FVSc4AvgJcV1UrgBeBS1v7S4EXq+oDwHWtHUlOAi4CPgysAr6R5LDZHIwkaXBTBkCNe6VtHt5eBZwF3N7qG4EL2vrqtk3bf3aStPqtVfX7qvolsAM4bVZGIUmatoG+A0hyWJJHgd3AZuC/gZeq6rXWZAxY0taXADsB2v6XgfdNrE9yzMRzrU2yNcnWPXv2TH9EkqSBDBQAVfV6VZ0MLGX8U/uHJmvWltnPvv3V33yuG6tqtKpGR0ZGBumeJGkGpnUXUFW9BNwHnAEsTrKo7VoK7GrrY8AygLb/vcDeifVJjpEkzbNB7gIaSbK4rb8T+ASwDbgX+HRrtga4s61vatu0/fdUVbX6Re0uoROBFcCDszUQSdL0LJq6CccDG9sdO28DbquqHyR5Erg1yZeBR4D1rf164FtJdjD+yf8igKp6IsltwJPAa8BlVfX67A5HkjSoKQOgqh4DTpmk/gyT3MVTVb8DLtzPe10DXDP9bkqSZpu/BJakThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkTk0ZAEmWJbk3ybYkTyS5vNWPTrI5yfa2PKrVk+T6JDuSPJbk1Anvtaa1355kzdwNS5I0lUGuAF4D/qWqPgScAVyW5CTgCmBLVa0AtrRtgHOBFe21FrgBxgMDWAecDpwGrNsXGpKk+TdlAFTV81X1s7b+W2AbsARYDWxszTYCF7T11cDNNe5+YHGS44FzgM1VtbeqXgQ2A6tmdTSSpIFN6zuAJMuBU4AHgOOq6nkYDwng2NZsCbBzwmFjrba/uiRpCAYOgCTvAr4HfL6qfnOgppPU6gD1N59nbZKtSbbu2bNn0O5JkqZpoABIcjjj//jfUlXfb+UX2tQObbm71ceAZRMOXwrsOkD9DarqxqoararRkZGR6YxFkjQNg9wFFGA9sK2qvjph1yZg3508a4A7J9QvbncDnQG83KaI7gZWJjmqffm7stUkSUOwaIA2ZwKfBR5P8mirfRG4FrgtyaXAc8CFbd9dwHnADuBV4BKAqtqb5GrgodbuqqraOyujkCRN25QBUFU/ZfL5e4CzJ2lfwGX7ea8NwIbpdFCSNDf8JbAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHVqkEdBSLNm+RU/HHYXZs2z154/7C5IB8UrAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1yofBSTO0kB5spz55BSBJnTIAJKlTBoAkdWrKAEiyIcnuJL+YUDs6yeYk29vyqFZPkuuT7EjyWJJTJxyzprXfnmTN3AxHkjSoQa4A/h1Y9abaFcCWqloBbGnbAOcCK9prLXADjAcGsA44HTgNWLcvNCRJwzFlAFTVT4C9byqvBja29Y3ABRPqN9e4+4HFSY4HzgE2V9XeqnoR2MxfhookaR7N9DuA46rqeYC2PLbVlwA7J7Qba7X91f9CkrVJtibZumfPnhl2T5I0ldn+EjiT1OoA9b8sVt1YVaNVNToyMjKrnZMk/dlMA+CFNrVDW+5u9TFg2YR2S4FdB6hLkoZkpgGwCdh3J88a4M4J9Yvb3UBnAC+3KaK7gZVJjmpf/q5sNUnSkEz5KIgk3wE+DhyTZIzxu3muBW5LcinwHHBha34XcB6wA3gVuASgqvYmuRp4qLW7qqre/MWyJGkeTRkAVfWZ/ew6e5K2BVy2n/fZAGyYVu8kSXPGXwJLUqcMAEnqlAEgSZ3y/wM4BPjceUlzwSsASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE7NewAkWZXk6SQ7klwx3+eXJI2b1wBIchjwb8C5wEnAZ5KcNJ99kCSNm+8rgNOAHVX1TFX9AbgVWD3PfZAkMf8BsATYOWF7rNUkSfNs0TyfL5PU6g0NkrXA2rb5SpKnD+J8xwC/Pojj3yoWyjjAsbwVLZRxkK8snLFwcH8ufz1Io/kOgDFg2YTtpcCuiQ2q6kbgxtk4WZKtVTU6G+81TAtlHOBY3ooWyjjAsUzXfE8BPQSsSHJikiOAi4BN89wHSRLzfAVQVa8l+SfgbuAwYENVPTGffZAkjZvvKSCq6i7grnk63axMJb0FLJRxgGN5K1oo4wDHMi2pqqlbSZIWHB8FIUmdWpABsFAeN5FkQ5LdSX4x7L4crCTLktybZFuSJ5JcPuw+zUSSdyR5MMnP2zi+NOw+HawkhyV5JMkPht2Xg5Hk2SSPJ3k0ydZh92emkixOcnuSp9rfl4/O2bkW2hRQe9zEfwF/z/htpw8Bn6mqJ4fasRlI8jHgFeDmqvrbYffnYCQ5Hji+qn6W5N3Aw8AFh9qfS5IAR1bVK0kOB34KXF5V9w+5azOW5J+BUeA9VfXJYfdnppI8C4xW1SH9O4AkG4H/rKqb2t2Sf1VVL83FuRbiFcCCedxEVf0E2DvsfsyGqnq+qn7W1n8LbOMQ/BV4jXulbR7eXofsp6gkS4HzgZuG3RdBkvcAHwPWA1TVH+bqH39YmAHg4ybe4pIsB04BHhhuT2amTZk8CuwGNlfVITmO5mvAF4A/Drsjs6CAHyd5uD1R4FD0fmAP8M02LXdTkiPn6mQLMQCmfNyEhifJu4DvAZ+vqt8Muz8zUVWvV9XJjP+S/bQkh+T0XJJPArur6uFh92WWnFlVpzL+tOHL2hTqoWYRcCpwQ1WdAvwfMGffYy7EAJjycRMajjZn/j3glqr6/rD7c7Dapfl9wKohd2WmzgQ+1ebObwXOSvIfw+3SzFXVrrbcDdzB+HTwoWYMGJtwVXk744EwJxZiAPi4ibeg9uXpemBbVX112P2ZqSQjSRa39XcCnwCeGm6vZqaqrqyqpVW1nPG/J/dU1T8OuVszkuTIdnMBbcpkJXDI3T1XVb8Cdib5YCudDczZjRLz/kvgubaQHjeR5DvAx4FjkowB66pq/XB7NWNnAp8FHm/z5wBfbL8MP5QcD2xsd5u9Dbitqg7p2ycXiOOAO8Y/Z7AI+HZV/Wi4XZqxzwG3tA+wzwCXzNWJFtxtoJKkwSzEKSBJ0gAMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOvX/NZDOi2CtuYIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's look at the disparity\n",
    "plt.hist(y, bins=[0,1,2,3,4,5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets see what's super correlated\n",
    "abs(train.corr()['Target']).sort_values(ascending=False)\n",
    "train = train.drop('Target', 1).copy()\n",
    "# notice I used absolute value because negative correlation matters jsut as much as positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put both test and training data together\n",
    "all_ = pd.concat((train, test), sort=True)\n",
    "#all_ = all_.drop('Id', 1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77384"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the nans\n",
    "all_.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                     0\n",
       "SQBage                 0\n",
       "SQBdependency          0\n",
       "SQBedjefe              0\n",
       "SQBescolari            0\n",
       "SQBhogar_nin           0\n",
       "SQBhogar_total         0\n",
       "SQBmeaned             36\n",
       "SQBovercrowding        0\n",
       "abastaguadentro        0\n",
       "abastaguafuera         0\n",
       "abastaguano            0\n",
       "age                    0\n",
       "agesq                  0\n",
       "area1                  0\n",
       "area2                  0\n",
       "bedrooms               0\n",
       "cielorazo              0\n",
       "computer               0\n",
       "coopele                0\n",
       "dependency             0\n",
       "dis                    0\n",
       "edjefa                 0\n",
       "edjefe                 0\n",
       "elimbasu1              0\n",
       "elimbasu2              0\n",
       "elimbasu3              0\n",
       "elimbasu4              0\n",
       "elimbasu5              0\n",
       "elimbasu6              0\n",
       "                   ...  \n",
       "r4m1                   0\n",
       "r4m2                   0\n",
       "r4m3                   0\n",
       "r4t1                   0\n",
       "r4t2                   0\n",
       "r4t3                   0\n",
       "refrig                 0\n",
       "rez_esc            27581\n",
       "rooms                  0\n",
       "sanitario1             0\n",
       "sanitario2             0\n",
       "sanitario3             0\n",
       "sanitario5             0\n",
       "sanitario6             0\n",
       "tamhog                 0\n",
       "tamviv                 0\n",
       "techocane              0\n",
       "techoentrepiso         0\n",
       "techootro              0\n",
       "techozinc              0\n",
       "television             0\n",
       "tipovivi1              0\n",
       "tipovivi2              0\n",
       "tipovivi3              0\n",
       "tipovivi4              0\n",
       "tipovivi5              0\n",
       "v14a                   0\n",
       "v18q                   0\n",
       "v18q1              25468\n",
       "v2a1               24263\n",
       "Length: 142, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see which columns have NaN\n",
    "all_.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQBmeaned\n",
      "meaneduc\n",
      "rez_esc\n",
      "v18q1\n",
      "v2a1\n"
     ]
    }
   ],
   "source": [
    "# lets jsut drop the ones with Nulls\n",
    "for i in all_:\n",
    "    if all_[i].isnull().sum() != 0:\n",
    "        print(i)\n",
    "        all_ = all_.drop(f\"{i}\", 1).copy()\n",
    "        #test = test.drop(f'{i}', 1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see if we got em all\n",
    "all_.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# would you look at that, nothing is crazy correlated so we can go ahead and save this as X\n",
    "all_ = pd.get_dummies(all_)\n",
    "#X = train.drop(['Target'], 1).copy()\n",
    "X_train = all_[:train.shape[0]]\n",
    "X_test = all_[train.shape[0]:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 15 candidates, totalling 30 fits\n",
      "[CV] max_depth=2, n_estimators=100 ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... max_depth=2, n_estimators=100, total=  11.2s\n",
      "[CV] max_depth=2, n_estimators=100 ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   13.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... max_depth=2, n_estimators=100, total=   7.7s\n",
      "[CV] max_depth=2, n_estimators=200 ...................................\n",
      "[CV] .................... max_depth=2, n_estimators=200, total=   8.0s\n",
      "[CV] max_depth=2, n_estimators=200 ...................................\n",
      "[CV] .................... max_depth=2, n_estimators=200, total=   8.0s\n",
      "[CV] max_depth=2, n_estimators=300 ...................................\n",
      "[CV] .................... max_depth=2, n_estimators=300, total=   8.4s\n",
      "[CV] max_depth=2, n_estimators=300 ...................................\n",
      "[CV] .................... max_depth=2, n_estimators=300, total=   9.7s\n",
      "[CV] max_depth=2, n_estimators=400 ...................................\n",
      "[CV] .................... max_depth=2, n_estimators=400, total=   9.9s\n",
      "[CV] max_depth=2, n_estimators=400 ...................................\n",
      "[CV] .................... max_depth=2, n_estimators=400, total=   9.9s\n",
      "[CV] max_depth=2, n_estimators=500 ...................................\n",
      "[CV] .................... max_depth=2, n_estimators=500, total=  10.2s\n",
      "[CV] max_depth=2, n_estimators=500 ...................................\n",
      "[CV] .................... max_depth=2, n_estimators=500, total=  10.6s\n",
      "[CV] max_depth=3, n_estimators=100 ...................................\n",
      "[CV] .................... max_depth=3, n_estimators=100, total=   9.0s\n",
      "[CV] max_depth=3, n_estimators=100 ...................................\n",
      "[CV] .................... max_depth=3, n_estimators=100, total=   9.3s\n",
      "[CV] max_depth=3, n_estimators=200 ...................................\n",
      "[CV] .................... max_depth=3, n_estimators=200, total=   9.3s\n",
      "[CV] max_depth=3, n_estimators=200 ...................................\n",
      "[CV] .................... max_depth=3, n_estimators=200, total=   9.3s\n",
      "[CV] max_depth=3, n_estimators=300 ...................................\n",
      "[CV] .................... max_depth=3, n_estimators=300, total=  10.0s\n",
      "[CV] max_depth=3, n_estimators=300 ...................................\n",
      "[CV] .................... max_depth=3, n_estimators=300, total=  10.0s\n",
      "[CV] max_depth=3, n_estimators=400 ...................................\n",
      "[CV] .................... max_depth=3, n_estimators=400, total=  10.6s\n",
      "[CV] max_depth=3, n_estimators=400 ...................................\n",
      "[CV] .................... max_depth=3, n_estimators=400, total=  10.7s\n",
      "[CV] max_depth=3, n_estimators=500 ...................................\n",
      "[CV] .................... max_depth=3, n_estimators=500, total=  11.3s\n",
      "[CV] max_depth=3, n_estimators=500 ...................................\n",
      "[CV] .................... max_depth=3, n_estimators=500, total=  11.5s\n",
      "[CV] max_depth=4, n_estimators=100 ...................................\n",
      "[CV] .................... max_depth=4, n_estimators=100, total=   9.2s\n",
      "[CV] max_depth=4, n_estimators=100 ...................................\n",
      "[CV] .................... max_depth=4, n_estimators=100, total=   9.1s\n",
      "[CV] max_depth=4, n_estimators=200 ...................................\n",
      "[CV] .................... max_depth=4, n_estimators=200, total=   9.9s\n",
      "[CV] max_depth=4, n_estimators=200 ...................................\n",
      "[CV] .................... max_depth=4, n_estimators=200, total=  10.4s\n",
      "[CV] max_depth=4, n_estimators=300 ...................................\n",
      "[CV] .................... max_depth=4, n_estimators=300, total=  11.2s\n",
      "[CV] max_depth=4, n_estimators=300 ...................................\n",
      "[CV] .................... max_depth=4, n_estimators=300, total=  10.7s\n",
      "[CV] max_depth=4, n_estimators=400 ...................................\n",
      "[CV] .................... max_depth=4, n_estimators=400, total=  11.0s\n",
      "[CV] max_depth=4, n_estimators=400 ...................................\n",
      "[CV] .................... max_depth=4, n_estimators=400, total=  11.6s\n",
      "[CV] max_depth=4, n_estimators=500 ...................................\n",
      "[CV] .................... max_depth=4, n_estimators=500, total=  12.7s\n",
      "[CV] max_depth=4, n_estimators=500 ...................................\n",
      "[CV] .................... max_depth=4, n_estimators=500, total=  12.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  6.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators='warn', n_jobs=-1, oob_score=False,\n",
       "            random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=1,\n",
       "       param_grid={'n_estimators': [100, 200, 300, 400, 500], 'max_depth': [2, 3, 4]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=2)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets do an initial random forest \n",
    "param_dictionary = {'n_estimators':[100,200,300,400,500], 'max_depth':[2,3,4]}\n",
    "RFC = RandomForestClassifier(n_jobs=-1, class_weight='balanced')#, max_depth=3)\n",
    "gs1 = GridSearchCV(RFC, param_dictionary, n_jobs=1, verbose=2, cv=2)\n",
    "gs1.fit(X_train,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 3, 'n_estimators': 300}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  20 out of  20 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators='warn', n_jobs=-1, oob_score=False,\n",
       "            random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=2,\n",
       "       param_grid={'n_estimators': [100, 200, 300, 400, 500], 'max_depth': [2, 3]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets do another grisdsearch using different scoring random forest \n",
    "param_dictionary = {'n_estimators':[100,200,300,400,500], 'max_depth':[2,3]}\n",
    "RFC = RandomForestClassifier(n_jobs=-1, class_weight='balanced')#, max_depth=3)\n",
    "gs2 = GridSearchCV(RFC, param_dictionary, n_jobs=2, verbose=2, cv=2, scoring='accuracy')\n",
    "gs2.fit(X_train,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 2, 'n_estimators': 400}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=3, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=300, n_jobs=-1, oob_score=False,\n",
       "            random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this seems to be a general consensus as our best bet\n",
    "poverty_submission1_model = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=3, n_estimators=300)\n",
    "poverty_submission1_model.fit(X_train,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6385895155383489\n"
     ]
    }
   ],
   "source": [
    "test = poverty_submission1_model.predict(X_train)\n",
    "print((test == y).sum()/len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1547556764675106"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(test)/len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.31      0.43      1731\n",
      "           2       0.31      0.48      0.38      1037\n",
      "           3       0.25      0.38      0.30       811\n",
      "           4       0.79      0.80      0.80      5978\n",
      "\n",
      "   micro avg       0.64      0.64      0.64      9557\n",
      "   macro avg       0.52      0.49      0.48      9557\n",
      "weighted avg       0.68      0.64      0.64      9557\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score_that = classification_report(test, y)\n",
    "print(score_that)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get them predictions\n",
    "poverty_submission1_model_predicitons = poverty_submission1_model.predict(X_test)\n",
    "poverty_submission1 = pd.DataFrame()\n",
    "poverty_submission1['Id'] = test_ID\n",
    "poverty_submission1['Target'] = poverty_submission1_model_predicitons\n",
    "poverty_submission1.to_csv('poverty_submission1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1731.,    0.,    0., 1037.,    0.,    0.,  811.,    0.,    0.,\n",
       "        5978.]),\n",
       " array([1. , 1.3, 1.6, 1.9, 2.2, 2.5, 2.8, 3.1, 3.4, 3.7, 4. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time for AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(data1,data2):\n",
    "    if len(data1) != len(data2):\n",
    "        raise ValueError(\"Not the same length man\")\n",
    "    print(\"Percent Correct: \", (data1 == data2).sum()/len(data1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=3)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ADA = AdaBoostClassifier(random_state=3)\n",
    "ADA.fit(X_train,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get them predictions\n",
    "poverty_submission2_model_predicitons = ADA.predict(X_test)\n",
    "poverty_submission2 = pd.DataFrame()\n",
    "poverty_submission2['Id'] = test_ID\n",
    "poverty_submission2['Target'] = poverty_submission2_model_predicitons\n",
    "poverty_submission2.to_csv('poverty_submission2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.31      0.50      0.39       475\n",
      "           2       0.37      0.41      0.39      1443\n",
      "           3       0.01      0.34      0.03        53\n",
      "           4       0.92      0.73      0.82      7586\n",
      "\n",
      "   micro avg       0.67      0.67      0.67      9557\n",
      "   macro avg       0.41      0.49      0.40      9557\n",
      "weighted avg       0.81      0.67      0.73      9557\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = ADA.predict(X_train)\n",
    "score_it = classification_report(preds, y)\n",
    "print(score_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 475.,    0.,    0., 1443.,    0.,    0.,   53.,    0.,    0.,\n",
       "        7586.]),\n",
       " array([1. , 1.3, 1.6, 1.9, 2.2, 2.5, 2.8, 3.1, 3.4, 3.7, 4. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Well, unfortunately I don't have more time to do this but I did learn a lot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall I learned how to do grid search cv and that was something I've been wanting to mess with and learn. Furthermore, selection was limited by time, as submissions were definitely not my friend on this assignment as they were much more tricky through the terminal. \n",
    "Usefulness- Honestly, this model is not very useful. I need to correct for the fact that our data is so skewed towards predicting 4, where it needs to think that every possibility is likely. Looking at the scores the mdoel got in the end, I think they scored based on having a fairly even distribution on the test set, an interesting mentatlity for scoring. Unfortunately this makes it difficult to fit a model as the model should be more liekly to predict the outcome that is more likely, a 4, but the test set is not designed as such."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
